{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ebay_scraper",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMNV0gHx5rGiFVi19hwflCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigibrb/Ebay-scraper-2021/blob/main/Ebay_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2Tj2YXM6BTl"
      },
      "source": [
        "import requests\n",
        "import bs4\n",
        "import re\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-NE9BOUDuVn"
      },
      "source": [
        "def scrape_advertisement(url):\n",
        "\n",
        "  p = requests.get(url)\n",
        "  page = bs4.BeautifulSoup(p.content,'lxml')\n",
        "  when = datetime.datetime.now()\n",
        "\n",
        "  try:\n",
        "    title = page.h1.text.replace(\"Details about  \\xa0\",\"\")\n",
        "  except:\n",
        "    title = 'Error: couldnt find the title'\n",
        "\n",
        "  try:\n",
        "    description = re.sub(\"\\s\\s+\" , \" \", str(page.find(class_='itemAttr').find(class_='section').table.text.replace('\\n',' ').replace('\\a',' ')))[0:199]\n",
        "  except:\n",
        "    description = 'Error: couldnt find any description'\n",
        "\n",
        "  if page.find(id='prcIsum_bidPrice') is not None:\n",
        "    bidprice = float(page.find(id='prcIsum_bidPrice').text.split()[1].replace(\"$\",\"\").replace(\"'\",\"\"))\n",
        "  else:\n",
        "    bidprice = 0\n",
        "\n",
        "  try:\n",
        "    bidnro = int(page.find(id='qty-test').text)\n",
        "  except:\n",
        "    bidnro = 'Error: couldnt find any number of bids'\n",
        "\n",
        "  try:\n",
        "    seller = page.find(class_='mbg-nw').text\n",
        "  except:\n",
        "    seller = 'Error: couldnt find the seller'\n",
        "\n",
        "  try:\n",
        "    sellscore = int(page.find(class_='mbg-l').text.split()[0].replace(\"(\",\"\"))\n",
        "  except:\n",
        "    sellscore = 'Error: couldnt find the sellers score'\n",
        "\n",
        "  try:\n",
        "    id = page.find(id='descItemNumber').text\n",
        "  except:\n",
        "    id = 'Error: couldnt find the id'\n",
        "    \n",
        "  return (id, title, bidprice, bidnro, when, seller, sellscore, description)\n",
        "\n",
        "\n",
        "\n",
        "def scrape_from_ebay(keyword, maximum_number_results = 100):\n",
        "\n",
        "  actual_number_results = 0\n",
        "  url = 'https://www.ebay.com/sch/i.html?_from=R40&_nkw='+keyword+'&LH_Auction=1'\n",
        "  p = requests.get(url)\n",
        "  page = bs4.BeautifulSoup(p.content)\n",
        "\n",
        "  page_count = []\n",
        "\n",
        "  for a in page.find(class_='pagination__items').findChildren(\"li\" , recursive=False):\n",
        "    page_count.append(a.text)\n",
        "\n",
        "  output = []\n",
        "\n",
        "  for page in page_count:\n",
        "    url = 'https://www.ebay.com/sch/i.html?_from=R40&_nkw='+keyword+'&LH_Auction=1&_pgn='+str(page)\n",
        "    print(\"Fetching links from page {} at address {} at this time {}\".format(page, url, datetime.datetime.now()))\n",
        "    p = requests.get(url)\n",
        "    page = bs4.BeautifulSoup(p.content)\n",
        "\n",
        "    for ad in page.find('ul', class_='srp-results srp-list clearfix').find_all(class_='s-item__link', href=True):\n",
        "      print('Scraping data from: {}'.format(ad['href']))\n",
        "      link_scraped = scrape_advertisement(ad['href'])\n",
        "      output.append(link_scraped)\n",
        "\n",
        "      actual_number_results += 1\n",
        "\n",
        "\n",
        "      if actual_number_results == maximum_number_results:\n",
        "        return pd.DataFrame(output, columns=['id', 'title', 'bidprice', 'bidnro', 'when', 'seller', 'sellscore', 'description'])\n",
        "        \n",
        "      time.sleep(0.1)\n",
        "\n",
        "  return pd.DataFrame(output, columns=['id', 'title', 'bidprice', 'bidnro', 'when', 'seller', 'sellscore', 'description'])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}